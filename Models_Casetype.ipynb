{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDq3rvqRoHaBxDzPa4OFfK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-AJ/CMPE255-SafeDose/blob/main/Models_Casetype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**This colab implements Multiclass classification algorithms to determine the type of case for those that are marked as 'Others' in the original dataset. The aim is to overcome the limitations of manually determining the type of case  due to incomplete/ explicit documentation of substance abuse. Several algorithms are tried and tested for performance, finally selecting the RandomForestCalssifier for predicting on the test set.**\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "WB0hEqN7_m2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "28Qi-FJEhU0Z"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report, precision_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN8RX-DShe3i",
        "outputId": "9e72b325-c113-4fc3-9c3f-c2b8edd0b681"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import data"
      ],
      "metadata": {
        "id": "mHmL8wcxL6pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read train and test data\n",
        "c_train = pd.read_csv('/content/drive/Shareddrives/CMPE255/data/pca/X_train_mca_casetype.csv')\n",
        "c_test = pd.read_csv('/content/drive/Shareddrives/CMPE255/data/pca/X_test_mca_casetype.csv')\n",
        "c_train = c_train.iloc[:, 1:]\n",
        "c_test = c_test.iloc[:, 1:]\n",
        "\n",
        "columns = ['CASETYPE_1', 'CASETYPE_2', 'CASETYPE_3', 'CASETYPE_4', 'CASETYPE_5', 'CASETYPE_6', 'CASETYPE_7']\n",
        "\n",
        "# Get X and y from train and test\n",
        "c_X_train = c_train.drop(columns, axis = 1)\n",
        "c_y_train = c_train[columns]\n",
        "\n",
        "X_test = c_test.drop(['CASETYPE_8'], axis = 1)\n",
        "\n",
        "# Reverse one hot encoding on casetype\n",
        "c_y_train['target'] = pd.get_dummies(c_y_train[columns]).idxmax(1)\n",
        "c_y_train.drop(columns, axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "FTPqbo9ajALb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the target class counts\n",
        "c_y_train.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk63pB-C7LZU",
        "outputId": "319be468-9145-4bbb-c8c9-000e5daee391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CASETYPE_4    85777\n",
              "CASETYPE_5    16810\n",
              "CASETYPE_2    13529\n",
              "CASETYPE_1     7872\n",
              "CASETYPE_3     7421\n",
              "CASETYPE_7     3125\n",
              "CASETYPE_6      768\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing SMOTE (Synthetic Minority Oversampling Technique) due to the class imbalance of CASETYPE. Oversampling ensures that they are near equal number of records for every CASETYPE which prevents bias towards the majority class and reduces possibility of poor classification of the minority classes."
      ],
      "metadata": {
        "id": "9MQg7RBQ7Rr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Oversample using SMOTE"
      ],
      "metadata": {
        "id": "KMcAixp_4idL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE\n",
        "sm = SMOTE(random_state = 42)\n",
        "X_smote, y_smote = sm.fit_resample(c_X_train, c_y_train)"
      ],
      "metadata": {
        "id": "KDO513gxrVoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train into train and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_smote, y_smote, test_size = 0.2, shuffle = True, stratify = y_smote, random_state = 42)"
      ],
      "metadata": {
        "id": "x2lP_1z2khhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape before oversampling')\n",
        "print('X_train = ', c_X_train.shape)\n",
        "\n",
        "print('Shape after oversampling and splitting into train and validation sets')\n",
        "print('X_train = ', X_train.shape)\n",
        "print('X_val = ', X_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLjnI_EXrfut",
        "outputId": "5420402f-92ee-4aa8-cf30-d6377462c7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before oversampling\n",
            "X_train =  (135302, 2)\n",
            "Shape after oversampling and splitting into train and validation sets\n",
            "X_train =  (480351, 2)\n",
            "X_val =  (120088, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-udkX0YM3LjP",
        "outputId": "42d17a47-23f0-4505-8bb7-7c92c9a7791f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CASETYPE_1    68622\n",
              "CASETYPE_6    68622\n",
              "CASETYPE_3    68622\n",
              "CASETYPE_2    68622\n",
              "CASETYPE_4    68621\n",
              "CASETYPE_5    68621\n",
              "CASETYPE_7    68621\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target classes in the training set are now balanced."
      ],
      "metadata": {
        "id": "zFIv_1BJ8oDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionary to store best parameter set and f1 score obtained from every model\n",
        "models = ['NaiveBayes', 'LogisticRegression', 'LightGBM', 'RandomForest', 'KneighborsClassifier']\n",
        "model_performance = {k:{} for k in models}"
      ],
      "metadata": {
        "id": "OfP785Ob8kS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "3DeTVpjl1GR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes Classifier\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predcit on validation set\n",
        "y_pred_val = nb.predict(X_val)\n",
        "\n",
        "# Calculate precision on validation set\n",
        "f1 = f1_score(y_val, y_pred_val, average = 'macro')\n",
        "precision = precision_score(y_val, y_pred_val, average = 'macro')\n",
        "\n",
        "# Save metrics to dictionary\n",
        "model_performance['NaiveBayes'] = {'prec':precision, 'f1':f1}"
      ],
      "metadata": {
        "id": "-46njZm01SHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "Ot9ELuduEsnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_val = lr.predict(X_val)\n",
        "\n",
        "# Calculate precision and f1 score on validation set\n",
        "f1 = f1_score(y_val, y_pred_val, average = 'macro')\n",
        "precision = precision_score(y_val, y_pred_val, average = 'macro')\n",
        "\n",
        "# Save metrics to dictionary\n",
        "model_performance['LogisticRegression'] = {'prec':precision, 'f1':f1}"
      ],
      "metadata": {
        "id": "uTH_JO8mcAMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "e6llX9Uv1gQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KneighborsClassifier \n",
        "knn = KNeighborsClassifier(n_neighbors = 4)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_val = knn.predict(X_val)\n",
        "\n",
        "# Calculate precision and f1 score on validation set\n",
        "f1 = f1_score(y_val, y_pred_val, average = 'macro')\n",
        "precision = precision_score(y_val, y_pred_val, average = 'macro')\n",
        "\n",
        "# Save metrics in dictionary\n",
        "model_performance['KneighborsClassifier'] = {'prec':precision, 'f1':f1}"
      ],
      "metadata": {
        "id": "j1fTCqzS1ux5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Light GBM"
      ],
      "metadata": {
        "id": "84rKBkijgoxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM\n",
        "gbc = LGBMClassifier(n_estimators = 100, learning_rate = 0.01, max_depth = 5, random_state = 11)\n",
        "gbc.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Predict on validation\n",
        "y_pred_val = gbc.predict(X_val)\n",
        "\n",
        "# Calculate precision and f1 score on validation set\n",
        "precision = precision_score(y_val, y_pred_val, average = 'macro')\n",
        "f1 = f1_score(y_val, y_pred_val, average = 'macro')\n",
        "\n",
        "# Store metrics in dict\n",
        "model_performance['LightGBM'] = {'prec':precision, 'f1':f1}"
      ],
      "metadata": {
        "id": "Q0FIBBL72iqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "Js1u--vQH0Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "forest = RandomForestClassifier(n_estimators = 50, min_samples_leaf = 1, min_samples_split = 2, random_state = 1)\n",
        "multi_target_forest = MultiOutputClassifier(forest, n_jobs = 2)\n",
        "\n",
        "# Fit on train set\n",
        "multi_target_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation\n",
        "y_pred_val = multi_target_forest.predict(X_val)\n",
        "\n",
        "# Calculate precision and f1 score on validation set\n",
        "f1 = f1_score(y_val, y_pred_val, average = 'macro')\n",
        "precision = precision_score(y_val, y_pred_val, average = 'macro')\n",
        "\n",
        "# Store in dict\n",
        "model_performance['RandomForest'] = {'prec':precision, 'f1':f1}"
      ],
      "metadata": {
        "id": "rpROyQS3dFCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose best performing model"
      ],
      "metadata": {
        "id": "hIeqxvJDLT-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " In predicting casetypes, precision is an important metric as the type of case would determine the next steps of treatment for the patient. Precision score tells us out of the predicted true/positive cases, how many were actually true/ positive for that particular casetype. Recall should also be considered as it is important that out of the actual positive case of each casetype, how many were correctly identified, which is given by recall. However, precision is more significant in our case, and hence precision is the primary metric and F1 score is the secondary metric."
      ],
      "metadata": {
        "id": "anQlhlWw9iPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the best performing model from the model_performance dictionary\n",
        "model_performance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1enBezgU_hOC",
        "outputId": "9b6c5015-2474-4c85-eae3-3b180282237b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NaiveBayes': {'prec': 0.4694479031174916, 'f1': 0.4184357830207569},\n",
              " 'LogisticRegression': {'prec': 0.39684318366591825, 'f1': 0.3475446677797421},\n",
              " 'LightGBM': {'prec': 0.5948406498947373, 'f1': 0.5787964770160663},\n",
              " 'RandomForest': {'prec': 0.8123381034762271, 'f1': 0.812707916098966},\n",
              " 'KneighborsClassifier': {'prec': 0.7964366269670303,\n",
              "  'f1': 0.7954894780225236}}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Prediction on validation set using the chosen model, and metrics"
      ],
      "metadata": {
        "id": "m7b8_4ckMFnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on validation\n",
        "y_pred_val = multi_target_forest.predict(X_val)\n",
        "\n",
        "# Prediction on test set\n",
        "y_pred_test = multi_target_forest.predict(X_test)"
      ],
      "metadata": {
        "id": "ix_rKwDIBi7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframes for predicted casetype and actual casetype\n",
        "predictions_test = pd.DataFrame(list(y_pred_test), columns = ['PRED_CASETYPE'])\n",
        "predictions_val = pd.DataFrame(list(y_pred_val), columns = ['PRED_CASETYPE'])\n",
        "\n",
        "casetypes = {\n",
        "    'CASETYPE_1' : 'Suicide Attempt',\n",
        "    'CASETYPE_2' : 'Seeking Detox',\n",
        "    'CASETYPE_3' : 'Alcohol consumed below 21 years',\n",
        "    'CASETYPE_4' : 'Adverse Reaction',\n",
        "    'CASETYPE_5' : 'Overmedication',\n",
        "    'CASETYPE_6' : 'Malicious Poisoning',\n",
        "    'CASETYPE_7': 'Accidental Ingestion'\n",
        "}\n",
        "\n",
        "# Map casetype number to casetype name\n",
        "predictions_test['PRED_CASETYPE'] = predictions_test['PRED_CASETYPE'].map(casetypes)\n",
        "predictions_val['PRED_CASETYPE'] = predictions_val['PRED_CASETYPE'].map(casetypes)\n",
        "\n",
        "y_val['target'] = y_val['target'].map(casetypes)"
      ],
      "metadata": {
        "id": "brVZRo1JRR2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0JEiHKlDLtd",
        "outputId": "38de21d7-4338-4b82-8cad-1d3a6ca888cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PRED_CASETYPE       \n",
              "Seeking Detox           42144\n",
              "Suicide Attempt         13380\n",
              "Malicious Poisoning     12038\n",
              "Overmedication           6730\n",
              "Adverse Reaction         6563\n",
              "Accidental Ingestion     2793\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the classifciation of the casetypes of the 'other' category. Since the target casetypes are unavailable, we look at the precision and f1 score on the validation set."
      ],
      "metadata": {
        "id": "_Op6I0fFdMWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification  report\n",
        "print(classification_report(y_val, predictions_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG6jzD_NNSMI",
        "outputId": "fbc7a488-ddd0-4093-befa-3f901d1a26e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 precision    recall  f1-score   support\n",
            "\n",
            "           Accidental Ingestion       0.80      0.83      0.81     17156\n",
            "               Adverse Reaction       0.70      0.67      0.69     17156\n",
            "Alcohol consumed below 21 years       1.00      1.00      1.00     17155\n",
            "            Malicious Poisoning       0.91      0.93      0.92     17155\n",
            "                 Overmedication       0.68      0.68      0.68     17156\n",
            "                  Seeking Detox       0.87      0.87      0.87     17155\n",
            "                Suicide Attempt       0.72      0.72      0.72     17155\n",
            "\n",
            "                       accuracy                           0.81    120088\n",
            "                      macro avg       0.81      0.81      0.81    120088\n",
            "                   weighted avg       0.81      0.81      0.81    120088\n",
            "\n"
          ]
        }
      ]
    }
  ]
}